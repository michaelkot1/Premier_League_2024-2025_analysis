{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "933b7ff7-e51b-433c-b54c-01620d1e5ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26cc05dc-23f4-4fa9-96d7-35072b3c38ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_name(name):\n",
    "    \"\"\"\n",
    "    Normalize a name by:\n",
    "    1. Converting to lowercase\n",
    "    2. Removing accents/diacritics\n",
    "    3. Stripping whitespace\n",
    "    \"\"\"\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    # Convert to string and normalize unicode\n",
    "    name = str(name)\n",
    "    # Normalize unicode characters (NFD = decomposed form)\n",
    "    name = unicodedata.normalize('NFD', name)\n",
    "    # Remove diacritics\n",
    "    name = ''.join(c for c in name if unicodedata.category(c) != 'Mn')\n",
    "    # Convert to lowercase and strip\n",
    "    return name.lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd95b49-b774-458d-8aa8-22dcc4417f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from rapidfuzz import fuzz, process\n",
    "    USE_RAPIDFUZZ = True\n",
    "except ImportError:\n",
    "    USE_RAPIDFUZZ = False\n",
    "    print(\"rapidfuzz not available, using difflib (slower but works)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a12be25-a79b-4c33-9dde-d6628e252f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_encoding_issues(name):\n",
    "    \"\"\"\n",
    "    Try to fix common encoding issues by attempting to decode/encode properly.\n",
    "    Handles mojibake (UTF-8 text incorrectly decoded as Latin-1).\n",
    "    \"\"\"\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    \n",
    "    name = str(name)\n",
    "    original_name = name\n",
    "    \n",
    "    # Common encoding fixes - try multiple strategies\n",
    "    if 'Ã' in name or 'Â' in name or 'Ä' in name or 'Å' in name or 'Å¡' in name or 'Å' in name or 'Ä' in name:\n",
    "        try:\n",
    "            # Strategy 1: UTF-8 text that was read as Latin-1\n",
    "            name = name.encode('latin-1').decode('utf-8')\n",
    "        except (UnicodeEncodeError, UnicodeDecodeError):\n",
    "            try:\n",
    "                # Strategy 2: Try Windows-1252 encoding\n",
    "                name = original_name.encode('windows-1252').decode('utf-8')\n",
    "            except (UnicodeEncodeError, UnicodeDecodeError):\n",
    "                try:\n",
    "                    # Strategy 3: Try cp1252\n",
    "                    name = original_name.encode('cp1252').decode('utf-8')\n",
    "                except (UnicodeEncodeError, UnicodeDecodeError):\n",
    "                    name = original_name\n",
    "    \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89ac2861-e863-4f32-ac38-2deb69dd8fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading player_possession_stats.csv...\n",
      "Reading player_salaries.csv...\n",
      "\n",
      "Player possession stats: 571 rows\n",
      "Player salaries: 729 rows\n",
      "Fixing encoding issues in player names...\n",
      "\n",
      "Unique players in possession stats: 559\n",
      "Unique players in salaries: 729\n",
      "\n",
      "Creating name mapping (this may take a moment)...\n",
      "\n",
      "Created 559 name mappings\n",
      "\n",
      "Sample mappings:\n",
      "\n",
      "Applying name mapping to player_possession...\n",
      "\n",
      "Merging dataframes...\n",
      "\n",
      "Merge complete!\n",
      "Total rows: 571\n",
      "Rows with salary data: 571\n",
      "Rows without salary data (NaN): 0\n",
      "Match rate: 100.00%\n",
      "\n",
      "Merged data saved to: /Users/michaelkot/Documents/prem_2025_stat_findings/csv_files_used/player_possession_with_salaries.csv\n"
     ]
    }
   ],
   "source": [
    "def create_name_mapping(possession_names, salary_names, threshold=85):\n",
    "    \"\"\"\n",
    "    Create a mapping dictionary from possession names to salary names using fuzzy matching.\n",
    "    \n",
    "    Args:\n",
    "        possession_names: list of names from player_possession_stats\n",
    "        salary_names: list of names from player_salaries\n",
    "        threshold: minimum similarity score (0-100) to consider a match\n",
    "    \n",
    "    Returns:\n",
    "        dict: mapping from possession_name -> salary_name\n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "    used_salary_names = set()\n",
    "    \n",
    "    # First, try exact matches (case-insensitive, normalized)\n",
    "    normalized_salary = {normalize_name(name): name for name in salary_names}\n",
    "    \n",
    "    for poss_name in possession_names:\n",
    "        if pd.isna(poss_name):\n",
    "            continue\n",
    "            \n",
    "        # Try exact match first (normalized)\n",
    "        normalized_poss = normalize_name(poss_name)\n",
    "        if normalized_poss in normalized_salary:\n",
    "            # Find the original salary name\n",
    "            for sal_name in salary_names:\n",
    "                if normalize_name(sal_name) == normalized_poss:\n",
    "                    mapping[poss_name] = sal_name\n",
    "                    used_salary_names.add(sal_name)\n",
    "                    break\n",
    "            continue\n",
    "        \n",
    "        # If no exact match, try fuzzy matching\n",
    "        if USE_RAPIDFUZZ:\n",
    "            # Get the best match from salary names\n",
    "            best_match, score, _ = process.extractOne(\n",
    "                poss_name, \n",
    "                salary_names, \n",
    "                scorer=fuzz.WRatio\n",
    "            )\n",
    "            \n",
    "            if score >= threshold and best_match not in used_salary_names:\n",
    "                mapping[poss_name] = best_match\n",
    "                used_salary_names.add(best_match)\n",
    "            else:\n",
    "                # Try with normalized names\n",
    "                normalized_poss = normalize_name(poss_name)\n",
    "                best_match_norm, score_norm, _ = process.extractOne(\n",
    "                    normalized_poss,\n",
    "                    [normalize_name(n) for n in salary_names],\n",
    "                    scorer=fuzz.WRatio\n",
    "                )\n",
    "                \n",
    "                if score_norm >= threshold:\n",
    "                    # Find the original salary name\n",
    "                    for sal_name in salary_names:\n",
    "                        if normalize_name(sal_name) == best_match_norm and sal_name not in used_salary_names:\n",
    "                            mapping[poss_name] = sal_name\n",
    "                            used_salary_names.add(sal_name)\n",
    "                            break\n",
    "        else:\n",
    "            # Use difflib as fallback\n",
    "            best_match = None\n",
    "            best_score = 0\n",
    "            \n",
    "            for sal_name in salary_names:\n",
    "                if sal_name in used_salary_names:\n",
    "                    continue\n",
    "                # Calculate similarity ratio\n",
    "                score = SequenceMatcher(None, poss_name.lower(), sal_name.lower()).ratio() * 100\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_match = sal_name\n",
    "            \n",
    "            if best_score >= threshold and best_match:\n",
    "                mapping[poss_name] = best_match\n",
    "                used_salary_names.add(best_match)\n",
    "            else:\n",
    "                # Try with normalized names\n",
    "                normalized_poss = normalize_name(poss_name)\n",
    "                best_match_norm = None\n",
    "                best_score_norm = 0\n",
    "                \n",
    "                for sal_name in salary_names:\n",
    "                    if sal_name in used_salary_names:\n",
    "                        continue\n",
    "                    normalized_sal = normalize_name(sal_name)\n",
    "                    score_norm = SequenceMatcher(None, normalized_poss, normalized_sal).ratio() * 100\n",
    "                    if score_norm > best_score_norm:\n",
    "                        best_score_norm = score_norm\n",
    "                        best_match_norm = sal_name\n",
    "                \n",
    "                if best_score_norm >= threshold and best_match_norm:\n",
    "                    mapping[poss_name] = best_match_norm\n",
    "                    used_salary_names.add(best_match_norm)\n",
    "    \n",
    "    return mapping\n",
    "\n",
    "def main():\n",
    "    # Read the CSV files\n",
    "    print(\"Reading player_possession_stats.csv...\")\n",
    "    player_possession = pd.read_csv('/Users/michaelkot/Documents/prem_2025_corr/prem_stats/player_possession_stats.csv')\n",
    "    \n",
    "    print(\"Reading player_salaries.csv...\")\n",
    "    player_salaries = pd.read_csv('/Users/michaelkot/Documents/prem_2025_corr/prem_stats/player_salaries.csv')\n",
    "    \n",
    "    # Clean up player_salaries as you mentioned\n",
    "    player_salaries = player_salaries.drop(columns=['Nation', 'Position', 'Team', 'Age', 'Weekly'])\n",
    "    \n",
    "    # Rename 'Player' to 'player' for consistency\n",
    "    player_salaries = player_salaries.rename(columns={'Player': 'player'})\n",
    "    \n",
    "    print(f\"\\nPlayer possession stats: {len(player_possession)} rows\")\n",
    "    print(f\"Player salaries: {len(player_salaries)} rows\")\n",
    "    \n",
    "    # Fix encoding issues in possession names first\n",
    "    print(\"Fixing encoding issues in player names...\")\n",
    "    # Store original names for reference\n",
    "    player_possession['player_original'] = player_possession['player'].copy()\n",
    "    # Fix encoding\n",
    "    player_possession['player'] = player_possession['player'].apply(fix_encoding_issues)\n",
    "    \n",
    "    # Get unique names from both dataframes\n",
    "    possession_names = player_possession['player'].unique().tolist()\n",
    "    salary_names = player_salaries['player'].unique().tolist()\n",
    "    \n",
    "    print(f\"\\nUnique players in possession stats: {len(possession_names)}\")\n",
    "    print(f\"Unique players in salaries: {len(salary_names)}\")\n",
    "    \n",
    "    # Create name mapping\n",
    "    print(\"\\nCreating name mapping (this may take a moment)...\")\n",
    "    name_mapping = create_name_mapping(possession_names, salary_names, threshold=85)\n",
    "    \n",
    "    print(f\"\\nCreated {len(name_mapping)} name mappings\")\n",
    "    \n",
    "    # Show some examples of mappings\n",
    "    print(\"\\nSample mappings:\")\n",
    "    for i, (old_name, new_name) in enumerate(list(name_mapping.items())[:10]):\n",
    "        if old_name != new_name:\n",
    "            print(f\"  '{old_name}' -> '{new_name}'\")\n",
    "    \n",
    "    # Apply the mapping to player_possession\n",
    "    print(\"\\nApplying name mapping to player_possession...\")\n",
    "    player_possession['player'] = player_possession['player'].map(name_mapping).fillna(player_possession['player'])\n",
    "    \n",
    "    # Drop the temporary original column\n",
    "    player_possession = player_possession.drop(columns=['player_original'])\n",
    "    \n",
    "    # Merge the dataframes\n",
    "    print(\"\\nMerging dataframes...\")\n",
    "    merged_df = player_possession.merge(player_salaries, on='player', how='left')\n",
    "    \n",
    "    # Check for NaN values in Annual column\n",
    "    nan_count = merged_df['Annual'].isna().sum()\n",
    "    total_count = len(merged_df)\n",
    "    match_rate = (1 - nan_count / total_count) * 100\n",
    "    \n",
    "    print(f\"\\nMerge complete!\")\n",
    "    print(f\"Total rows: {total_count}\")\n",
    "    print(f\"Rows with salary data: {total_count - nan_count}\")\n",
    "    print(f\"Rows without salary data (NaN): {nan_count}\")\n",
    "    print(f\"Match rate: {match_rate:.2f}%\")\n",
    "    \n",
    "    # Show players that didn't match\n",
    "    if nan_count > 0:\n",
    "        print(\"\\nPlayers without salary matches:\")\n",
    "        unmatched = merged_df[merged_df['Annual'].isna()]['player'].unique()\n",
    "        for player in sorted(unmatched)[:20]:  # Show first 20\n",
    "            print(f\"  - {player}\")\n",
    "        if len(unmatched) > 20:\n",
    "            print(f\"  ... and {len(unmatched) - 20} more\")\n",
    "    \n",
    "    # Save the merged dataframe\n",
    "    output_path = '/Users/michaelkot/Documents/prem_2025_stat_findings/csv_files_used/player_possession_with_salaries.csv'\n",
    "    merged_df.to_csv(output_path, index=False)\n",
    "    print(f\"\\nMerged data saved to: {output_path}\")\n",
    "    \n",
    "    return merged_df, name_mapping\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    merged_df, name_mapping = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcc1c15-c6d7-41f4-a602-cbd9e1a79b33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7221899b-38ee-4996-99a5-9c9bfeeb55e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
